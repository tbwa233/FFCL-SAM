{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9c15ab3-2e25-4373-9c8d-8267336174b1",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa86567-d5af-4dbe-a05c-e4cc1b36e404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score,confusion_matrix,ConfusionMatrixDisplay,accuracy_score,roc_auc_score\n",
    "import copy\n",
    "import tqdm\n",
    "import time\n",
    "import torchvision\n",
    "from collections import defaultdict\n",
    "from torch.optim import lr_scheduler\n",
    "import wandb\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebfc1c6-6a02-43d0-ad22-c455b1a7a4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_paths={\n",
    "    'train_positive':'../data/train_patient_level/positive_patch_overlapped_v4/',\n",
    "    'train_negative':'../data/train_patient_level/negative_patch_overlapped_v4/',\n",
    "    'val_positive':'../data/val_patient_level/positive_patch_overlapped_v4/',\n",
    "    'val_negative':'../data/val_patient_level/negative_patch_overlapped_v4/',\n",
    "    'test_positive':'../data/test_patient_level/positive_patch_overlapped_v4/',\n",
    "    'test_negative':'../data/test_patient_level/negative_patch_overlapped_v4/'  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cfd865-c0ca-4e4f-8bc7-ec72ba083142",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\n",
    "    'random_seed':48,\n",
    "    'IM_W':64,\n",
    "    'IM_H':64,\n",
    "    'Batch':10,\n",
    "    'device':torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'ds_type':'binary_cls',\n",
    "    'LR':0.0001,\n",
    "    'epoch':50,\n",
    "    'local_contrastive_epoch':50,\n",
    "    'global_contrastive_epoch':50,\n",
    "    'contrastive_early_stopping':True,\n",
    "    'early_stop_patience':5,\n",
    "    'model':'resnet18',\n",
    "    'train_type':'ffcl',\n",
    "    'imgnet_pretrained':True,\n",
    "    'loss_fn':'focal',\n",
    "    'positive_patches_train':-1,\n",
    "    'negative_patches_train':-1,\n",
    "    'positive_patches_val':-1,\n",
    "    'negative_patches_val':-1,\n",
    "    'positive_patches_test':-1,\n",
    "    'negative_patches_test':-1,\n",
    "    'focal_alpha':0.8,\n",
    "    'focal_gamma':3.0,\n",
    "    'scheduler_warmup':1,\n",
    "    'scheduler':'cos',\n",
    "    'scheduler_step':15\n",
    "}\n",
    "\n",
    "config['saved_model_name']=config['ds_type']+'_'+config['model']+'_'+config['train_type']+'_'+str(len(os.listdir('saved_models'))+1)\n",
    "torch.manual_seed(config['random_seed'])\n",
    "np.random.seed(config['random_seed'])\n",
    "config['patch_paths']=patch_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fd4f61-0872-4380-bdab-4577680169d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"FFCL_margin.ipynb\"\n",
    "# wandb.login()\n",
    "\n",
    "wandb.init(\n",
    "    entity='atik',\n",
    "    group=config['ds_type'],\n",
    "    name=\"FFCL: step=3 (positive), Focal, ResNet-18, random samples (New 4 data training)\",\n",
    "    project=\"margin\",\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58f9d95-4d34-46a0-8698-f4230144c149",
   "metadata": {},
   "source": [
    "# Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0664d85-030d-4587-8de5-00dd23789f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['ds_type']=='binary_cls':\n",
    "    print(\"Dealing with binary_cls dataset\")\n",
    "    positive_patch_train=os.listdir(patch_paths['train_positive'])  \n",
    "    positive_patch_train=[patch_paths['train_positive']+s for s in positive_patch_train]\n",
    "    \n",
    "    negative_patch_train=os.listdir(patch_paths['train_negative'])\n",
    "    negative_patch_train=[patch_paths['train_negative']+s for s in negative_patch_train]\n",
    "    \n",
    "    x_train=positive_patch_train+negative_patch_train\n",
    "    y_train=[0]*len(positive_patch_train) + [1]*len(negative_patch_train)\n",
    "    \n",
    "    config['pos_weight']=len(os.listdir(patch_paths['train_positive']))/len(os.listdir(patch_paths['train_negative']))\n",
    "    config['positive_patches_train']=len(positive_patch_train)\n",
    "    config['negative_patches_train']=len(negative_patch_train)\n",
    "   \n",
    "    positive_patch_val=os.listdir(patch_paths['val_positive'])  \n",
    "    positive_patch_val=[patch_paths['val_positive']+s for s in positive_patch_val]\n",
    "    \n",
    "    negative_patch_val=os.listdir(patch_paths['val_negative'])\n",
    "    negative_patch_val=[patch_paths['val_negative']+s for s in negative_patch_val]\n",
    "    \n",
    "    x_val=positive_patch_val+negative_patch_val\n",
    "    y_val=[0]*len(positive_patch_val) + [1]*len(negative_patch_val)\n",
    "\n",
    "    config['positive_patches_val']=len(positive_patch_val)\n",
    "    config['negative_patches_val']=len(negative_patch_val)\n",
    " \n",
    "    positive_patch_test=os.listdir(patch_paths['test_positive']) \n",
    "    positive_patch_test=[patch_paths['test_positive']+s for s in positive_patch_test]\n",
    "     \n",
    "    negative_patch_test=os.listdir(patch_paths['test_negative'])\n",
    "    negative_patch_test=[patch_paths['test_negative']+s for s in negative_patch_test]\n",
    "    \n",
    "    x_test=positive_patch_test+negative_patch_test\n",
    "    y_test=[0]*len(positive_patch_test) + [1]*len(negative_patch_test)\n",
    "\n",
    "    config['positive_patches_test']=len(positive_patch_test)\n",
    "    config['negative_patches_test']=len(negative_patch_test)\n",
    "    \n",
    "    x_train=np.array(x_train)\n",
    "    y_train=np.array(y_train)\n",
    "    \n",
    "    x_val=np.array(x_val)\n",
    "    y_val=np.array(y_val)\n",
    "    \n",
    "    x_test=np.array(x_test)\n",
    "    y_test=np.array(y_test)\n",
    "    \n",
    "config[\"classes\"]=len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44b5d07-4f97-48b1-ba1c-676d6d37f244",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generate_Contrastive_data(Dataset):\n",
    "    def __init__(self,length,data_type,transform=None):\n",
    "        self.transform = transform\n",
    "        self.length=length\n",
    "        self.data_type=data_type\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.data_type=='train':\n",
    "          image1=cv2.imread(x_train[idx],0)\n",
    "          \n",
    "          another_idx=np.random.randint(0,self.length)\n",
    "\n",
    "          if config['ds_type']=='binary_cls':\n",
    "            while another_idx==idx:\n",
    "              another_idx=np.random.randint(0,self.length)\n",
    "          image2=cv2.imread(x_train[another_idx],0)\n",
    "\n",
    "          if self.transform:\n",
    "            image1=self.transform(image=image1)[\"image\"]\n",
    "            image2=self.transform(image=image2)[\"image\"]\n",
    "            image1=(image1-torch.min(image1))/(torch.max(image1)-torch.min(image1))\n",
    "            image2=(image2-torch.min(image2))/(torch.max(image2)-torch.min(image2))\n",
    "\n",
    "          label1=y_train[idx]\n",
    "          label2=y_train[another_idx]\n",
    "\n",
    "          return [image1,image2,label1,label2]\n",
    "        \n",
    "        if self.data_type=='val':\n",
    "          image1=cv2.imread(x_val[idx],0)\n",
    "          another_idx=np.random.randint(0,self.length)\n",
    "          if config['ds_type']=='binary_cls':\n",
    "            while another_idx==idx:\n",
    "              another_idx=np.random.randint(0,self.length)\n",
    "          image2=cv2.imread(x_val[another_idx],0)\n",
    "          \n",
    "          if self.transform:\n",
    "            image1=self.transform(image=image1)[\"image\"]\n",
    "            image2=self.transform(image=image2)[\"image\"]\n",
    "            image1=(image1-torch.min(image1))/(torch.max(image1)-torch.min(image1))\n",
    "            image2=(image2-torch.min(image2))/(torch.max(image2)-torch.min(image2))\n",
    "          \n",
    "          label1=y_val[idx]\n",
    "          label2=y_val[another_idx]\n",
    "\n",
    "          return [image1,image2,label1,label2]\n",
    "\n",
    "\n",
    "transform_train = A.Compose(\n",
    "    [\n",
    "        A.Resize(width=config['IM_W'], height=config['IM_H']),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_test = A.Compose(\n",
    "    [\n",
    "       \n",
    "        A.Resize(width=config['IM_W'], height=config['IM_H'],p=1),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "contrastive_train_set = Generate_Contrastive_data(length=x_train.shape[0],data_type='train', transform = transform_train)\n",
    "contrastive_valid_set = Generate_Contrastive_data(length=x_val.shape[0],data_type='val', transform = transform_test)\n",
    "\n",
    "ffa_dataloader = {\n",
    "    'train': DataLoader(contrastive_train_set, batch_size=config['Batch'], shuffle=True, num_workers=0),\n",
    "    'val': DataLoader(contrastive_valid_set, batch_size=config['Batch'], shuffle=False, num_workers=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d83f01d-1ddf-44ce-90e2-7403fb1ce61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(preds,labels,metrics,loss_fn,class_weights=None):\n",
    "    preds=preds.squeeze()\n",
    "    loss=loss_fn(preds,labels)\n",
    "    # print(loss)\n",
    "    metrics['loss'] += loss.data.cpu().numpy() * labels.size(0)\n",
    "    return loss\n",
    "\n",
    "def cosine_similarity(x1,x2,y1,y2,metrics=None):\n",
    "    \n",
    "    cos_sim=nn.CosineEmbeddingLoss()\n",
    "    x1_fl=torch.flatten(x1,start_dim=1)\n",
    "    x2_fl=torch.flatten(x2,start_dim=1)\n",
    "    y_vectors=torch.zeros(size=(y1.shape[0],))\n",
    "    y_vectors=y_vectors.to(config['device'])\n",
    "    for i in range(y1.shape[0]):\n",
    "        if y1[i].item()==y2[i].item():\n",
    "            y_vectors[i]=1\n",
    "        else:\n",
    "            y_vectors[i]=-1\n",
    "    cos_sim_loss=cos_sim(x1_fl,x2_fl,y_vectors)\n",
    "    if metrics is not None:\n",
    "        metrics['loss'] = metrics['loss']+cos_sim_loss.data.cpu().numpy() * y1.size(0)\n",
    "    return cos_sim_loss\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Implemented From https://www.kaggle.com/code/hmendonca/efficientnetb4-fastai-blindness-detection?scriptVersionId=19310748&cellId=16\"\"\"\n",
    "    def __init__(self, gamma=config['focal_gamma'], reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        CE_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-CE_loss)\n",
    "        F_loss = ((1 - pt)**self.gamma) * CE_loss\n",
    "        if self.reduction == 'sum':\n",
    "            return F_loss.sum()\n",
    "        elif self.reduction == 'mean':\n",
    "            return F_loss.mean()\n",
    "\n",
    "class FocalLoss_BCE(nn.Module):\n",
    "    #implemented from https://www.kaggle.com/code/bigironsphere/loss-function-library-keras-pytorch\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(FocalLoss_BCE, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, alpha=config['focal_alpha'], gamma=config['focal_gamma'], smooth=1):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        #inputs = torch.nn.Sigmoid()(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        bce=torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
    "        #first compute binary cross-entropy \n",
    "        BCE = bce(inputs, targets)\n",
    "        BCE_EXP = torch.exp(-BCE)\n",
    "        focal_loss = alpha * (1-BCE_EXP)**gamma * BCE\n",
    "                       \n",
    "        return focal_loss\n",
    "\n",
    "def calc_acc(preds,labels,metrics):\n",
    "    if config[\"classes\"]==2:\n",
    "        sig=nn.Sigmoid()\n",
    "        preds=sig(preds)\n",
    "        preds[preds < 0.5] = 0\n",
    "        preds[preds >= 0.5] = 1\n",
    "    else:\n",
    "        softmax=nn.Softmax()\n",
    "        preds=softmax(preds)\n",
    "        _, preds = torch.max(preds, 1)\n",
    "\n",
    "    preds = preds.long().squeeze()\n",
    "    preds=preds.data.cpu().numpy()\n",
    "    labels=labels.data.cpu().numpy()\n",
    "    preds=preds.flatten()\n",
    "    labels=labels.flatten()\n",
    "\n",
    "    acc=accuracy_score(labels,preds) * labels.shape[0]\n",
    "    metrics['Acc.'] += acc\n",
    "\n",
    "def calc_other_metric(preds,labels,metrics):\n",
    "    if config[\"classes\"]==2:\n",
    "        sig=nn.Sigmoid()\n",
    "        preds=sig(preds)\n",
    "        preds[preds < 0.5] = 0\n",
    "        preds[preds >= 0.5] = 1\n",
    "    else:\n",
    "        softmax=nn.Softmax()\n",
    "        preds=softmax(preds)\n",
    "        _, preds = torch.max(preds, 1)\n",
    "\n",
    "    preds=preds.data.cpu().numpy()\n",
    "    labels=labels.data.cpu().numpy()\n",
    "    preds=preds.flatten()\n",
    "    labels=labels.flatten()\n",
    "\n",
    "    f1=f1_score(labels,preds,average = 'macro')* labels.shape[0]\n",
    "    metrics['F1_Score'] +=f1\n",
    "\n",
    "    p_score=precision_score(labels,preds,average='macro')* labels.shape[0]\n",
    "    metrics['Precision'] +=p_score\n",
    "\n",
    "    r_score=recall_score(labels,preds,average='macro')* labels.shape[0]\n",
    "    metrics['Recall'] +=r_score\n",
    "    \n",
    "def print_metrics(metrics, epoch_samples, phase):\n",
    "    outputs = []\n",
    "    for k in metrics.keys():\n",
    "        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
    "\n",
    "    print(\"{}: {}\".format(phase, \", \".join(outputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a2a9de-6613-455d-b125-b0942f0d5c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"model\"]==\"resnet18\":\n",
    "    model = models.resnet18(pretrained=config['imgnet_pretrained'])\n",
    "    model.conv1=nn.Conv2d(in_channels=1,out_channels=64, kernel_size=(7,7),stride=(2,2),padding=(3,3),bias=False)\n",
    "elif config[\"model\"]==\"resnet50\":\n",
    "    print(\"loading ResNet50\")\n",
    "    model = models.resnet50(pretrained=False)\n",
    "elif config[\"model\"]==\"resnet34\":\n",
    "    print(\"loading resnet34\")\n",
    "    model = models.resnet34(pretrained=False)\n",
    "elif config[\"model\"]==\"resnext50\":\n",
    "    print(\"loading resnext 50\")\n",
    "    model=models.resnext50_32x4d()\n",
    "elif config[\"model\"]==\"vgg19\":\n",
    "    print(\"loading VGG-19\")\n",
    "    model=models.vgg19(pretrained=False)\n",
    "elif config[\"model\"]==\"effnetv2s\":\n",
    "    print(\"loading effnetv2s\")\n",
    "    model=models.efficientnet_v2_s()\n",
    "\n",
    "elif config[\"model\"]==\"vgg16\":\n",
    "    print(\"loading VGG-16\")\n",
    "    model=models.vgg16(pretrained=False)\n",
    "model=model.to(config['device'])\n",
    "\n",
    "all_layers = []\n",
    "def get_individual_layer(network):\n",
    "    for layer in network.children():\n",
    "        if list(layer.children()) != []:\n",
    "            get_individual_layer(layer)\n",
    "        if list(layer.children()) == []: \n",
    "            all_layers.append(layer)\n",
    "get_individual_layer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46c9aa5-fc05-40aa-bf4e-09e8ecfeddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list=[]\n",
    "val_loss_list=[]\n",
    "\n",
    "def train_ffa_contrastive_model(model,opt, scheduler, num_epochs=25):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "\n",
    "    tolerance_count=0\n",
    "    loss_fn=torch.nn.CosineEmbeddingLoss() \n",
    "    for epoch in range(num_epochs):\n",
    "        if config['contrastive_early_stopping']==True:\n",
    "            if tolerance_count>=config['early_stop_patience']:\n",
    "                print(\"EARLY STOPPED\")\n",
    "                break \n",
    "        \n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('~' * 10)\n",
    "\n",
    "        since = time.time()\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                \n",
    "                for param_group in opt.param_groups:\n",
    "                    print(\"LR\", param_group['lr'])\n",
    "\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            metrics = defaultdict(float)\n",
    "            epoch_samples = 0\n",
    "            batch_loss=0\n",
    "            num_batch=0\n",
    "            for btch,feed_dict in enumerate(tqdm.tqdm(ffa_dataloader[phase])):\n",
    "\n",
    "                inputs1=feed_dict[0]\n",
    "                inputs2=feed_dict[1]\n",
    "                labels1=feed_dict[2]\n",
    "                labels2=feed_dict[3]\n",
    "\n",
    "\n",
    "                inputs1 = inputs1.to(config['device'])\n",
    "                inputs2 = inputs2.to(config['device'])\n",
    "\n",
    "                # labels = labels.type(torch.LongTensor)\n",
    "                labels1 = labels1.type(torch.FloatTensor)\n",
    "                labels2 = labels2.type(torch.FloatTensor)\n",
    "\n",
    "\n",
    "                labels1 = labels1.to(config['device'])\n",
    "                labels2 = labels2.to(config['device'])\n",
    "                y_vectors=torch.zeros(size=(labels1.shape[0],))\n",
    "                y_vectors=y_vectors.to(config['device'])\n",
    "                for i in range(labels1.shape[0]):\n",
    "                    if labels1[i].item()==labels2[i].item():\n",
    "                        y_vectors[i]=1\n",
    "                    else:\n",
    "                        y_vectors[i]=-1\n",
    "               \n",
    "                pred1=inputs1 \n",
    "                pred2=inputs2\n",
    "\n",
    "                overall_loss=0\n",
    "                num_layers=0\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    #####################################Local Contrastie Learning################################\n",
    "                    for i in range(len(all_layers)):     \n",
    "                        # print(all_layers[i])      \n",
    "                        if isinstance(all_layers[i],torch.nn.Conv2d): # check if current layer is a CNN\n",
    "                            if pred1.shape[1]==all_layers[i].in_channels: # Skipping the downsample module in-case of resnet      \n",
    "                                pred1=nn.ReLU()(all_layers[i].forward(pred1)) # Forward Pass\n",
    "                                pred2=nn.ReLU()(all_layers[i].forward(pred2)) # Forward Pass\n",
    "\n",
    "                                x1_fl=torch.flatten(pred1,start_dim=1)\n",
    "                                x2_fl=torch.flatten(pred2,start_dim=1)\n",
    "\n",
    "                                loss=loss_fn(x1_fl,x2_fl,y_vectors) # calculate loss for this module\n",
    "                                ### Learn this module locally\n",
    "                                \n",
    "                                if phase == 'train':\n",
    "                                    opt.zero_grad()\n",
    "                                    loss.backward(retain_graph=False)\n",
    "                                    opt.step()\n",
    "                                overall_loss+=loss.item()\n",
    "                                num_layers+=1\n",
    "                                pred1=pred1.detach() # Detaching from the gradient-computation graph\n",
    "                                pred2=pred2.detach() # Detaching from the gradient-computation graph\n",
    "                            \n",
    "\n",
    "\n",
    "                        else: #incase other layer (e.g: BatchNorm )\n",
    "                            if isinstance(all_layers[i],torch.nn.Linear):\n",
    "                                pred1=torch.flatten(pred1,start_dim=1)\n",
    "                                pred2=torch.flatten(pred2,start_dim=1)\n",
    "                                pred1=nn.ReLU()(all_layers[i].forward(pred1)) # Forward pass\n",
    "                                pred2=nn.ReLU()(all_layers[i].forward(pred2)) # Forward pass\n",
    "                                x1_fl=pred1\n",
    "                                x2_fl=pred2\n",
    "                            else: #incase it is not linear layer (e.g: batch norm)\n",
    "                                pred1=all_layers[i].forward(pred1) # Forward pass\n",
    "                                pred2=all_layers[i].forward(pred2) # Forward pass\n",
    "                                x1_fl=torch.flatten(pred1,start_dim=1)\n",
    "                                x2_fl=torch.flatten(pred2,start_dim=1)\n",
    "\n",
    "                            if isinstance(all_layers[i],(torch.nn.Dropout,torch.nn.ReLU,torch.nn.MaxPool2d,torch.nn.AdaptiveAvgPool2d,torch.nn.SiLU,torch.nn.Sigmoid,torchvision.ops.StochasticDepth))==False:\n",
    "                                #print(all_layers[i])\n",
    "                                # Learning the current module except Non-learnable layers (e.g: ReLu layer), since it is not learnable and does not have any grad_fn. However, the outputs goes through this layer as well\n",
    "                                # print(all_layers[i])\n",
    "                                loss=loss_fn(x1_fl,x2_fl,y_vectors) # calculate loss for this module\n",
    "                                if phase=='train':\n",
    "                                    opt.zero_grad() \n",
    "                                    loss.backward(retain_graph=False)\n",
    "                                    opt.step()\n",
    "                                overall_loss+=loss.item()\n",
    "                                num_layers+=1\n",
    "                        \n",
    "                            pred1=pred1.detach()\n",
    "                            pred2=pred2.detach() \n",
    "                    \n",
    "               \n",
    "                overall_loss=overall_loss/num_layers\n",
    "                # overall_loss+= loss_global.item()\n",
    "                batch_loss+=overall_loss\n",
    "                num_batch+=1\n",
    "            epoch_loss=batch_loss/num_batch\n",
    "            if phase=='train':\n",
    "                print(phase,\"Loss: \",epoch_loss)\n",
    "                train_loss_list.append(epoch_loss)\n",
    "                wandb.log({\"train ffa loss\":epoch_loss})\n",
    "            if phase=='val':\n",
    "                print(phase,\"Loss: \",epoch_loss)\n",
    "                val_loss_list.append(epoch_loss)\n",
    "                if epoch_loss<best_loss:\n",
    "                    torch.save(model.state_dict(), 'saved_models/'+config['saved_model_name']+'ffa_pretrained')\n",
    "                    best_loss=epoch_loss\n",
    "                    tolerance_count=0\n",
    "                    print(\"Saving best model\")\n",
    "                else:\n",
    "                    tolerance_count+=1\n",
    "                wandb.log({\"val ffa loss\":epoch_loss})\n",
    "\n",
    "        scheduler.step()                \n",
    "        time_elapsed = time.time() - since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "        #print('val loss: ',epoch_loss,' val acc: ',epoch_acc,' val f1 ',epoch_f1)\n",
    "\n",
    "    \n",
    "    print('Best val loss: {:4f}'.format(min(val_loss_list)))\n",
    "    # print('Best val acc: {:4f}'.format(max(val_acc_list)))\n",
    "    # print('Best val f1: {:4f}'.format(max(val_f1_list)))\n",
    "    # print('Best val prec: {:4f}'.format(max(val_precision_list)))\n",
    "    # print('Best val recall: {:4f}'.format(max(val_recall_list)))\n",
    "     # load best model weights\n",
    "    #model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "\"\"\"\n",
    "Model is trained with adam optimizer \n",
    "and saved everytime if current epoch loss is less than the observed best validation loss\n",
    "\"\"\"\n",
    "# Define optimizer\n",
    "optimizer_ft = torch.optim.Adam(model.parameters(), lr=config['LR'],weight_decay=1e-5)\n",
    "# Define LR scheduler\n",
    "cos_lr_scheduler = lr_scheduler.CosineAnnealingLR(optimizer_ft, T_max=config['local_contrastive_epoch'], eta_min=0,verbose=True)\n",
    "\n",
    "model = train_ffa_contrastive_model(model, optimizer_ft, cos_lr_scheduler, num_epochs=config['local_contrastive_epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985fb2d2-98d9-40e2-b5a5-2523e797b7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('saved_models/'+config['saved_model_name']+'ffa_pretrained'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5328018c-9554-4349-91ba-a546ef487bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list=[]\n",
    "val_loss_list=[]\n",
    "\n",
    "def train_global_contrastive_model(model,opt, scheduler, num_epochs=25):\n",
    "    # scaler = torch.cuda.amp.GradScaler()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "    #best_acc=-1\n",
    "    #best_f1 = -1\n",
    "    tolerance_count=0\n",
    "    loss_fn=torch.nn.CosineEmbeddingLoss() \n",
    "    for epoch in range(num_epochs):\n",
    "        if config['contrastive_early_stopping']==True:\n",
    "            if tolerance_count>=config['early_stop_patience']:\n",
    "                print(\"EARLY STOPPED\")\n",
    "                break \n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('~' * 10)\n",
    "\n",
    "        since = time.time()\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                \n",
    "                for param_group in opt.param_groups:\n",
    "                    print(\"LR\", param_group['lr'])\n",
    "\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            metrics = defaultdict(float)\n",
    "            epoch_samples = 0\n",
    "            batch_loss=0\n",
    "            num_batch=0\n",
    "            for btch,feed_dict in enumerate(tqdm.tqdm(ffa_dataloader[phase])):\n",
    "\n",
    "                inputs1=feed_dict[0]    \n",
    "                inputs2=feed_dict[1]\n",
    "                labels1=feed_dict[2]\n",
    "                labels2=feed_dict[3]\n",
    "\n",
    "\n",
    "                inputs1 = inputs1.to(config['device'])\n",
    "                inputs2 = inputs2.to(config['device'])\n",
    "\n",
    "                # labels = labels.type(torch.LongTensor)\n",
    "                labels1 = labels1.type(torch.FloatTensor)\n",
    "                labels2 = labels2.type(torch.FloatTensor)\n",
    "\n",
    "\n",
    "                labels1 = labels1.to(config['device'])\n",
    "                labels2 = labels2.to(config['device'])\n",
    "                y_vectors=torch.zeros(size=(labels1.shape[0],))\n",
    "                y_vectors=y_vectors.to(config['device'])\n",
    "                for i in range(labels1.shape[0]):\n",
    "                    if labels1[i].item()==labels2[i].item():\n",
    "                        y_vectors[i]=1\n",
    "                    else:\n",
    "                        y_vectors[i]=-1\n",
    "               \n",
    "                pred1=inputs1 \n",
    "                pred2=inputs2\n",
    "\n",
    "                overall_loss=0\n",
    "                num_layers=0\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    ###########################Global Contrastive Leraning#######################\n",
    "                    pred1=model(inputs1)\n",
    "                    pred2=model(inputs2)\n",
    "                    loss_global=loss_fn(pred1,pred2,y_vectors)\n",
    "                    if phase=='train':\n",
    "                        opt.zero_grad()\n",
    "                        loss_global.backward()\n",
    "                        opt.step()\n",
    "                # overall_loss=overall_loss/num_layers\n",
    "                overall_loss+= loss_global.item()\n",
    "                batch_loss+=overall_loss\n",
    "                num_batch+=1\n",
    "            epoch_loss=batch_loss/num_batch\n",
    "            if phase=='train':\n",
    "                print(phase,\"Loss: \",epoch_loss)\n",
    "                train_loss_list.append(epoch_loss)\n",
    "                wandb.log({\"train Global loss\":epoch_loss})\n",
    "            if phase=='val':\n",
    "                print(phase,\"Loss: \",epoch_loss)\n",
    "                val_loss_list.append(epoch_loss)\n",
    "                if epoch_loss<best_loss:\n",
    "                    torch.save(model.state_dict(), 'saved_models/'+config['saved_model_name']+'global_contrastive')\n",
    "                    best_loss=epoch_loss\n",
    "                    tolerance_count=0\n",
    "                else:\n",
    "                    tolerance_count+=1\n",
    "                wandb.log({\"val Global loss\":epoch_loss})\n",
    "\n",
    "        scheduler.step()                \n",
    "        time_elapsed = time.time() - since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "        #print('val loss: ',epoch_loss,' val acc: ',epoch_acc,' val f1 ',epoch_f1)\n",
    "\n",
    "    \n",
    "    print('Best val loss: {:4f}'.format(min(val_loss_list)))\n",
    "    # print('Best val acc: {:4f}'.format(max(val_acc_list)))\n",
    "    # print('Best val f1: {:4f}'.format(max(val_f1_list)))\n",
    "    # print('Best val prec: {:4f}'.format(max(val_precision_list)))\n",
    "    # print('Best val recall: {:4f}'.format(max(val_recall_list)))\n",
    "     # load best model weights\n",
    "    #model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "\"\"\"\n",
    "Model is trained with adam optimizer \n",
    "\n",
    "and saved everytime if current epoch loss is less than the observed best validation loss\n",
    "\"\"\"\n",
    "# Define optimizer\n",
    "optimizer_ft = torch.optim.Adam(model.parameters(), lr=config['LR'],weight_decay=1e-5)\n",
    "# Define LR scheduler\n",
    "cos_lr_scheduler = lr_scheduler.CosineAnnealingLR(optimizer_ft, T_max=wandb.config['global_contrastive_epoch'], eta_min=0,verbose=True)\n",
    "\n",
    "model = train_global_contrastive_model(model, optimizer_ft, cos_lr_scheduler, num_epochs=wandb.config['global_contrastive_epoch'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fdd164-2967-4f6d-983f-8a7f5f43b13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('saved_models/'+wandb.config['saved_model_name']+'global_contrastive'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e175909d-7820-41e2-acd9-b27248e1be0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generate_data(Dataset):\n",
    "    def __init__(self,length,data_type,transform=None):\n",
    "        self.transform = transform\n",
    "        self.length=length\n",
    "        self.data_type=data_type\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.data_type=='train':\n",
    "          image=cv2.imread(x_train[idx],0)\n",
    "\n",
    "          \n",
    "          if self.transform:\n",
    "            image=self.transform(image=image)[\"image\"]\n",
    "            image=(image-torch.min(image))/(torch.max(image)-torch.min(image))\n",
    "\n",
    "\n",
    "          \n",
    "          #print(image.shape)\n",
    "          label=y_train[idx]\n",
    "          return [image,label]\n",
    "        \n",
    "        if self.data_type=='val':\n",
    "          image=cv2.imread(x_val[idx],0)\n",
    "          \n",
    "\n",
    "          # image=Image.fromarray(image)\n",
    "\n",
    "          # image=torch.cuda.FloatTensor(image)\n",
    "\n",
    "          if self.transform:\n",
    "            image=self.transform(image=image)[\"image\"]\n",
    "            image=(image-torch.min(image))/(torch.max(image)-torch.min(image))\n",
    "\n",
    "    \n",
    "          label=y_val[idx]\n",
    "          return [image,label]\n",
    "        if self.data_type=='test':\n",
    "          image=cv2.imread(x_test[idx],0)\n",
    "          image=self.transform(image=image)[\"image\"]\n",
    "          image=(image-torch.min(image))/(torch.max(image)-torch.min(image))\n",
    "          label=y_test[idx]\n",
    "          return [image,label]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "transform_train = A.Compose(\n",
    "    [\n",
    "        A.Resize(width=config['IM_W'], height=config['IM_H']),\n",
    "        # A.RandomCrop(height=728, width=728),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        # A.Blur(p=0.3),\n",
    "        # A.CLAHE(p=0.3),\n",
    "        # A.ColorJitter(p=0.3),\n",
    "        # A.CoarseDropout(max_holes=12, max_height=20, max_width=20, p=0.3),\n",
    "        # A.IAAAffine(shear=30, rotate=0, p=0.2, mode=\"constant\"),\n",
    "        # A.Normalize(\n",
    "        #     mean=[0.485, 0.456, 0.406],\n",
    "        #     std=[0.229, 0.224, 0.225],    \n",
    "        #     max_pixel_value=255.0\n",
    "        # ),\n",
    "        # torchvision.transforms.ToPILImage(),\n",
    "        # torchvision.transforms.ToTensor()\n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")\n",
    "transform_test = A.Compose(\n",
    "    [\n",
    "        A.Resize(width=config['IM_W'], height=config['IM_H']),\n",
    "        # A.Normalize(\n",
    "        #     mean=[0.485, 0.456, 0.406],\n",
    "        #     std=[0.229, 0.224, 0.225],    \n",
    "        #     max_pixel_value=255.0\n",
    "        # ),\n",
    "        ToTensorV2()\n",
    "\n",
    "    ]\n",
    ")\n",
    "train_set = Generate_data(length=x_train.shape[0],data_type='train', transform = transform_train)\n",
    "valid_set = Generate_data(length=x_val.shape[0],data_type='val', transform = transform_test)\n",
    "test_set = Generate_data(length=x_test.shape[0],data_type='test', transform = transform_test)\n",
    "# cls_weights = class_weight.compute_class_weight(class_weight='balanced',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33dc63e-5c41-4143-8fbf-1de9360b4446",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {\n",
    "    'train': train_set, 'val': valid_set, 'test': test_set\n",
    "}\n",
    "\n",
    "dataloader = {\n",
    "    'train': DataLoader(train_set, batch_size=config['Batch'], shuffle=True, num_workers=0),\n",
    "    'val': DataLoader(valid_set, batch_size=config['Batch'], shuffle=True, num_workers=0),\n",
    "    'test': DataLoader(test_set, batch_size=config['Batch'], shuffle=False, num_workers=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8079b89-a4e3-46c9-bd75-48e9a9eae1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_list=[]\n",
    "val_acc_list=[]\n",
    "\n",
    "train_f1_list=[]\n",
    "val_f1_list=[]\n",
    "\n",
    "train_precision_list=[]\n",
    "val_precision_list=[]\n",
    "\n",
    "train_recall_list=[]\n",
    "val_recall_list=[]\n",
    "\n",
    "train_loss_list=[]\n",
    "val_loss_list=[]\n",
    "\n",
    "\n",
    "train_kappa_list=[]\n",
    "def train_model(optimizer, scheduler,loss_fn, num_epochs=25):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "    best_test_loss=1e10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('~' * 10)\n",
    "\n",
    "        since = time.time()\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                \n",
    "                for param_group in optimizer.param_groups:\n",
    "                    print(\"LR\", param_group['lr'])\n",
    "\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            metrics = defaultdict(float)\n",
    "            epoch_samples = 0\n",
    "\n",
    "            for btch,feed_dict in enumerate(tqdm.tqdm(dataloader[phase])):\n",
    "                inputs=feed_dict[0]\n",
    "                labels=feed_dict[1]\n",
    "                inputs = inputs.to(config['device'])\n",
    "                if config['classes']>2:\n",
    "                    labels = labels.type(torch.LongTensor)\n",
    "                else:\n",
    "                    labels = labels.type(torch.FloatTensor)\n",
    "                labels = labels.to(config['device'])\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)      \n",
    "                    # print(outputs.shape)          \n",
    "                    # loss = ordinal_mse(outputs, labels, metrics,loss_fn)\n",
    "                    # loss = l1_loss_compute(outputs,labels,metrics,loss_fn)\n",
    "                    # outputs=preds2onehot(outputs)\n",
    "                    loss=calc_loss(outputs,labels,metrics,loss_fn)\n",
    "                    # outputs=get_one_hot_classification(outputs)\n",
    "\n",
    "                    \n",
    "                    #print(loss)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        #print(\"BP\")\n",
    "                        optimizer.step()\n",
    "                    calc_acc(outputs, labels,metrics)#no return just calc Acc.\n",
    "                    calc_other_metric(outputs,labels,metrics)\n",
    "                # statistics\n",
    "                epoch_samples += inputs.size(0) #number of total samples in one epoch\n",
    "\n",
    "            #after each epoch ends the following lines prints and measures the metrics\n",
    "            print_metrics(metrics, epoch_samples, phase)\n",
    "            epoch_loss = metrics['loss'] / epoch_samples\n",
    "            epoch_acc = metrics['Acc.'] / epoch_samples\n",
    "            epoch_f1 = metrics['F1_Score'] / epoch_samples\n",
    "            epoch_prec= metrics['Precision'] / epoch_samples\n",
    "            epoch_recall= metrics['Recall'] / epoch_samples\n",
    "            # epoch_auc= metrics['auc'] / epoch_samples\n",
    "\n",
    "            \n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val':\n",
    "                if epoch_loss<best_loss:\n",
    "                    # best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    best_loss=epoch_loss\n",
    "                    torch.save(model.state_dict(), 'saved_models/'+wandb.config['saved_model_name'])\n",
    "                    print(\"saving model: \",wandb.config['saved_model_name'])\n",
    "\n",
    "                # val_acc_list.append(epoch_acc.item())\n",
    "                # val_loss_list.append(epoch_loss)\n",
    "                # val_recall_list.append(epoch_recall)\n",
    "                # val_precision_list.append(epoch_prec)\n",
    "                # val_f1_list.append(epoch_f1)\n",
    "\n",
    "                wandb.log({\"val loss\":epoch_loss,\n",
    "                           \"val acc\":epoch_acc,\n",
    "                           \"val f1\":epoch_f1, \n",
    "                           \"val recall\":epoch_recall,\n",
    "                           \"val prec\":epoch_prec                    \n",
    "                         })\n",
    "            if phase=='train':\n",
    "                train_acc_list.append(epoch_acc.item())\n",
    "                train_loss_list.append(epoch_loss)\n",
    "                train_recall_list.append(epoch_recall)\n",
    "                train_precision_list.append(epoch_prec)\n",
    "                train_f1_list.append(epoch_f1) \n",
    "\n",
    "                wandb.log({\"train loss\":epoch_loss,\n",
    "                           \"train acc\":epoch_acc,\n",
    "                           \"train f1\":epoch_f1, \n",
    "                           \"train recall\":epoch_recall,\n",
    "                           \"train prec\":epoch_prec\n",
    "                })\n",
    "                scheduler.step()\n",
    "            # if phase=='test':\n",
    "            #     if epoch_loss<best_test_loss:\n",
    "            #         # best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            #         best_test_loss=epoch_loss\n",
    "            #         torch.save(model.state_dict(), 'saved_models/'+config['saved_model_name']+'_best_test')\n",
    "            #     wandb.log({\"test loss\":epoch_loss,\n",
    "            #                \"test acc\":epoch_acc,\n",
    "            #                \"test f1\":epoch_f1, \n",
    "            #                \"test recall\":epoch_recall,\n",
    "            #                \"test prec\":epoch_prec\n",
    "            #     },step=epoch)\n",
    "                           \n",
    "            #   if epoch_acc>best_acc:\n",
    "            #     best_acc=epoch_acc\n",
    "            #   if epoch_f1>best_f1:\n",
    "            #     best_f1=epoch_f1 \n",
    "            #   if epoch_prec>best              \n",
    "                \n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "        #print('val loss: ',epoch_loss,' val acc: ',epoch_acc,' val f1 ',epoch_f1)\n",
    "\n",
    "    \n",
    "    # print('Best val loss: {:4f}'.format(min(val_loss_list)))\n",
    "    # print('Best val acc: {:4f}'.format(max(val_acc_list)))\n",
    "    # print('Best val f1: {:4f}'.format(max(val_f1_list)))\n",
    "    # print('Best val prec: {:4f}'.format(max(val_precision_list)))\n",
    "    # print('Best val recall: {:4f}'.format(max(val_recall_list)))\n",
    "     # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c39ce2-62d6-4e1c-b1a4-a64660931a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"model\"]==\"vgg19\" or config[\"model\"]==\"vgg16\":\n",
    "    num_ftrs = model.classifier[6].in_features\n",
    "    if config[\"classes\"]>2:\n",
    "        model.classifier[6] = torch.nn.Linear(num_ftrs,config[\"classes\"])\n",
    "    else:\n",
    "        model.classifier[6] = torch.nn.Linear(num_ftrs,1)\n",
    "elif config[\"model\"]==\"effnetv2s\":\n",
    "    num_ftrs=model.classifier[1].in_features \n",
    "    if config[\"classes\"]>2:\n",
    "        model.classifier[1] = torch.nn.Linear(num_ftrs,config[\"classes\"])\n",
    "    else:\n",
    "        model.classifier[1] = torch.nn.Linear(num_ftrs,1)      \n",
    "else:\n",
    "    num_ftrs = model.fc.in_features\n",
    "    if config[\"classes\"]>2:\n",
    "        model.fc = torch.nn.Linear(num_ftrs,config[\"classes\"])\n",
    "    else:\n",
    "        model.fc = torch.nn.Linear(num_ftrs,1)\n",
    "model=model.to(config['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c869b8-235f-4d15-9bd4-ac9cf8d5694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model is trained with adam optimizer \n",
    "and saved everytime if current epoch loss is less than the observed best validation loss\n",
    "\"\"\"\n",
    "# Define optimizer\n",
    "optimizer_ft = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=config['LR'],weight_decay=1e-5)\n",
    "# Define LR scheduler\n",
    "cos_lr_scheduler = lr_scheduler.CosineAnnealingLR(optimizer_ft, T_max=config['epoch'], eta_min=0,verbose=True)\n",
    "# step_lr=lr_scheduler.StepLR(optimizer=optimizer_ft,step_size=30,verbose=True,gamma=0.1)\n",
    "# Define loss function\n",
    "# cls_weights=torch.cuda.FloatTensor(cls_weights)\n",
    "# loss_fn=nn.MSELoss()\n",
    "# loss_fn = FocalLoss()\n",
    "# loss_fn=torch.nn.L1Loss()\n",
    "# loss_fn=loss_fn.cuda()\n",
    "# \n",
    "if config['loss_fn']=='focal':\n",
    "    print(\"training with focal loss\")\n",
    "    loss_fn=FocalLoss_BCE()\n",
    "elif config['loss_fn']=='bce_weight':\n",
    "    loss_fn=torch.nn.BCEWithLogitsLoss(pos_weight=torch.from_numpy(np.array(config['pos_weight'])))\n",
    "elif config['loss_fn']=='bce':\n",
    "    print(\"Loading Regular BCE\")\n",
    "    loss_fn=torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "\n",
    "# wandb.watch(model) #for watching convergence of the model\n",
    "model = train_model(optimizer_ft, cos_lr_scheduler,loss_fn, num_epochs=config['epoch'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176b1422-70e4-4445-8503-cb9cd8ed8478",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('saved_models/'+wandb.config['saved_model_name']))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdda695-6e6b-4a17-8c71-935eaf1b6753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_results():\n",
    "  y_test_pred=np.empty(0)\n",
    "  y_test_gt=np.empty(0)\n",
    "  model.eval()\n",
    "  y_test_pred_logits=np.empty(0)\n",
    "  for inputs,labels in dataloader['test']:\n",
    "    inputs = inputs.to(config['device'])\n",
    "    outputs = model(inputs)\n",
    "    # print(outputs)\n",
    "    # outputs=labels\n",
    "    \n",
    "\n",
    "    if config[\"classes\"]==2:\n",
    "        sig=nn.Sigmoid()\n",
    "        outputs=sig(outputs)\n",
    "        # print(outputs)\n",
    "\n",
    "        output_logits=outputs\n",
    "        output_logits=output_logits.data.cpu().numpy()\n",
    "        y_test_pred_logits=np.append(y_test_pred_logits,output_logits)\n",
    "\n",
    "        # print(output_logits)\n",
    "        outputs[outputs < 0.5] = 0\n",
    "        outputs[outputs >= 0.5] = 1\n",
    "        \n",
    "    else:\n",
    "        softmax=nn.Softmax()\n",
    "        outputs=softmax(outputs)\n",
    "        _, outputs = torch.max(outputs, 1)\n",
    "    # _, outputs = torch.max(outputs, 1)#pred contains the max valued index\n",
    "    outputs=outputs.data.cpu().numpy()\n",
    "    \n",
    "    # print(output_logits)\n",
    "    # outputs=np.argmax(outputs,axis=1)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    # print(y_test_pred_logits)\n",
    "    # print(y_test_pred_logits.shape)\n",
    "    y_test_pred=np.append(y_test_pred,outputs)\n",
    "    labels=labels.data.cpu().numpy()\n",
    "    y_test_gt=np.append(y_test_gt,labels)\n",
    "\n",
    "  # print(y_test_pred_logits)\n",
    "  return y_test_pred,y_test_gt,y_test_pred_logits\n",
    "y_test_pred,y_test_gt,y_test_pred_logits=get_test_results()\n",
    "\n",
    "conf_matrix=confusion_matrix(y_test_gt,y_test_pred)\n",
    "conf_disp=ConfusionMatrixDisplay(conf_matrix,display_labels=set(y_test_gt))\n",
    "# wandb.plot.confusion_matrix(probs=None,y_true=y_test_gt, preds=y_test_pred)\n",
    "\n",
    "# conf_disp.plot()\n",
    "\n",
    "# plt.savefig(config['saved_model_name']+'_'+\"conf_mat_test.png\")\n",
    "\n",
    "wandb.log({\"test conf\" :wandb.plot.confusion_matrix(probs=None,\n",
    "                        y_true=y_test_gt, preds=y_test_pred,title=\"test conf\")\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52c4506-c2b4-4a5a-8739-9ec070237e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['classes']>2:\n",
    "        print({\"test acc\":float(accuracy_score(y_test_gt,y_test_pred)),\n",
    "                \"test f1\":float(f1_score(y_test_gt,y_test_pred,average = 'macro')), \n",
    "                \"test recall\":float(recall_score(y_test_gt,y_test_pred,average = 'macro')),\n",
    "                \"test prec\":float(precision_score(y_test_gt,y_test_pred,average = 'macro'))# ,\n",
    "                #\"test auc \":float(roc_auc_score(y_test_gt,y_test_pred_logits))\n",
    "        })\n",
    "else:\n",
    "        \n",
    "        print({\"test acc\":float(accuracy_score(y_test_gt,y_test_pred)),\n",
    "                \"test f1\":float(f1_score(y_test_gt,y_test_pred,average = 'macro')), \n",
    "                \"test recall\":float(recall_score(y_test_gt,y_test_pred,average = 'macro')),\n",
    "                \"test prec\":float(precision_score(y_test_gt,y_test_pred,average = 'macro')) ,\n",
    "                \"test auc \":float(roc_auc_score(y_test_gt,y_test_pred_logits))\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deb9b1f-9ea8-4677-9114-67c1ee72626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc=float(accuracy_score(y_test_gt,y_test_pred))\n",
    "test_f1=float(f1_score(y_test_gt,y_test_pred,average='macro'))\n",
    "test_recall=float(recall_score(y_test_gt,y_test_pred,average='macro'))\n",
    "test_prec=float(precision_score(y_test_gt,y_test_pred,average='macro')) \n",
    "\n",
    "if config['classes']==2:\n",
    "    test_auc =float(roc_auc_score(y_test_gt,y_test_pred_logits))\n",
    "    columns = [\"Test Acc\", \"Test F1\", \"Test Prec\", \"Test Recall\", \"Test Auc\"]\n",
    "    data = [[test_acc,test_f1,test_prec,test_recall,test_auc]]\n",
    "else:\n",
    "    columns = [\"Test Acc\", \"Test F1\", \"Test Prec\", \"Test Recall\"]\n",
    "    data = [[test_acc,test_f1,test_prec,test_recall]]\n",
    "\n",
    "test_table=wandb.Table(columns=columns,data=data) \n",
    "wandb.log({\"Test Table\": test_table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b382f1-1f16-4c3e-95cd-ebf56f2a80a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
